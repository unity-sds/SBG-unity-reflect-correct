{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7940462-0604-453e-bb6f-5a1d21c0800b",
   "metadata": {},
   "source": [
    "SBG - Spectral Resample Process - Application Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e2815e-0ec7-4b9e-a127-7a835de23370",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 18:45:47,625\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "import hytools as ht\n",
    "from hytools.io import parse_envi_header, write_envi_header\n",
    "from hytools.io.envi import WriteENVI\n",
    "from hytools.brdf import calc_flex_single,set_solar_zn\n",
    "from hytools.topo import calc_scsc_coeffs\n",
    "from hytools.masks import mask_create\n",
    "from hytools.misc import set_brdf\n",
    "from PIL import Image\n",
    "import pystac\n",
    "import spectral.io.envi as envi\n",
    "\n",
    "from unity_sds_client.resources.dataset import Dataset\n",
    "from unity_sds_client.resources.data_file import DataFile\n",
    "\n",
    "# stage_in packages\n",
    "from unity_sds_client.resources.collection import Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a82a76-59c2-4f72-87ff-73a5daa82bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "anc_names = ['path_length','sensor_az','sensor_zn',\n",
    "                'solar_az', 'solar_zn','phase','slope',\n",
    "                'aspect', 'cosine_i','utc_time','']\n",
    "\n",
    "\n",
    "# Hard-code configuration dictionary\n",
    "#######################################################\n",
    "config_dict = {}\n",
    "config_dict[\"topo\"] =  {}\n",
    "config_dict[\"topo\"]['type'] =  'scs+c'\n",
    "config_dict[\"topo\"]['calc_mask'] = [[\"ndi\", {'band_1': 850,'band_2': 660,\n",
    "                                             'min': 0.1,'max': 1.0}],\n",
    "                                    ['ancillary',{'name':'slope',\n",
    "                                                  'min': np.radians(5),'max':'+inf' }],\n",
    "                                    ['ancillary',{'name':'cosine_i',\n",
    "                                                  'min': 0.12,'max':'+inf' }]]\n",
    "config_dict[\"topo\"]['apply_mask'] = [[\"ndi\", {'band_1': 850,'band_2': 660,\n",
    "                                             'min': 0.1,'max': 1.0}],\n",
    "                                    ['ancillary',{'name':'slope',\n",
    "                                                  'min': np.radians(5),'max':'+inf' }],\n",
    "                                    ['ancillary',{'name':'cosine_i',\n",
    "                                                  'min': 0.12,'max':'+inf' }]]\n",
    "config_dict[\"topo\"]['c_fit_type'] = 'nnls'\n",
    "\n",
    "config_dict[\"brdf\"] = {}\n",
    "config_dict[\"brdf\"]['type'] =  'flex'\n",
    "config_dict[\"brdf\"]['grouped'] =  False\n",
    "config_dict[\"brdf\"]['geometric'] = 'li_dense_r'\n",
    "config_dict[\"brdf\"]['volume'] = 'ross_thick'\n",
    "config_dict[\"brdf\"][\"b/r\"] = 2.5\n",
    "config_dict[\"brdf\"][\"h/b\"] = 2\n",
    "config_dict[\"brdf\"]['sample_perc'] = 0.1\n",
    "config_dict[\"brdf\"]['interp_kind'] = 'linear'\n",
    "config_dict[\"brdf\"]['calc_mask'] = [[\"ndi\", {'band_1': 850,'band_2': 660,\n",
    "                                              'min': 0.1,'max': 1.0}]]\n",
    "config_dict[\"brdf\"]['apply_mask'] = [[\"ndi\", {'band_1': 850,'band_2': 660,\n",
    "                                              'min': 0.1,'max': 1.0}]]\n",
    "config_dict[\"brdf\"]['bin_type'] = 'dynamic'\n",
    "config_dict[\"brdf\"]['num_bins'] = 18\n",
    "config_dict[\"brdf\"]['ndvi_bin_min'] = 0.1\n",
    "config_dict[\"brdf\"]['ndvi_bin_max'] = 1.0\n",
    "config_dict[\"brdf\"]['ndvi_perc_min'] = 10\n",
    "config_dict[\"brdf\"]['ndvi_perc_max'] = 95\n",
    "\n",
    "config_dict[\"glint\"]  = {}\n",
    "config_dict['glint']['type'] = 'gao'\n",
    "config_dict['glint']['correction_wave'] = 860\n",
    "config_dict['glint']['apply_mask'] =  [[\"ndi\", {'band_1': 850,'band_2': 660,\n",
    "                                              'min': -1,'max': 0.}],\n",
    "                                       [\"band\", {'band': 560,\n",
    "                                              'min': 0,'max': 0.2}]]\n",
    "config_dict['glint']['truncate'] = True\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "110f3fb5-c488-4108-87c3-af634d4082e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quicklook(input_file):\n",
    "\n",
    "    img = ht.HyTools()\n",
    "    img.read_file(input_file)\n",
    "    image_file = input_file.replace('.bin','.png')\n",
    "\n",
    "    if 'DESIS' in img.base_name:\n",
    "        band3 = img.get_wave(560)\n",
    "        band2 = img.get_wave(850)\n",
    "        band1 = img.get_wave(660)\n",
    "    else:\n",
    "        band3 = img.get_wave(560)\n",
    "        band2 = img.get_wave(850)\n",
    "        band1 = img.get_wave(1660)\n",
    "\n",
    "    rgb=  np.stack([band1,band2,band3])\n",
    "    rgb[rgb == img.no_data] = np.nan\n",
    "\n",
    "    rgb = np.moveaxis(rgb,0,-1).astype(float)\n",
    "    bottom = np.nanpercentile(rgb,5,axis = (0,1))\n",
    "    top = np.nanpercentile(rgb,95,axis = (0,1))\n",
    "    rgb = np.clip(rgb,bottom,top)\n",
    "    rgb = (rgb-np.nanmin(rgb,axis=(0,1)))/(np.nanmax(rgb,axis= (0,1))-np.nanmin(rgb,axis= (0,1)))\n",
    "    rgb = (rgb*255).astype(np.uint8)\n",
    "\n",
    "    im = Image.fromarray(rgb)\n",
    "    im.save(image_file)\n",
    "\n",
    "\n",
    "def generate_stac_metadata(header_file):\n",
    "\n",
    "    header = envi.read_envi_header(header_file)\n",
    "    base_name = os.path.basename(header_file)[:-4]\n",
    "\n",
    "    metadata = {}\n",
    "    metadata['id'] = base_name\n",
    "    metadata['start_datetime'] = dt.datetime.strptime(header['start acquisition time'], \"%Y-%m-%dt%H:%M:%Sz\")\n",
    "    metadata['end_datetime'] = dt.datetime.strptime(header['end acquisition time'], \"%Y-%m-%dt%H:%M:%Sz\")\n",
    "    # Split corner coordinates string into list\n",
    "    coords = [float(x) for x in header['bounding box'].replace(']', '').replace('[', '').split(',')]\n",
    "    geometry = [list(x) for x in zip(coords[::2], coords[1::2])]\n",
    "    # Add first coord to the end of the list to close the polygon\n",
    "    geometry.append(geometry[0])\n",
    "    metadata['geometry'] = {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": geometry\n",
    "    }\n",
    "    base_tokens = base_name.split('_')\n",
    "    metadata['collection'] = f\"SISTER_{base_tokens[1]}_{base_tokens[2]}_{base_tokens[3]}_{base_tokens[5]}\"\n",
    "    metadata['properties'] = {\n",
    "        'sensor': base_tokens[1],\n",
    "        'description': header['description'],\n",
    "        'product': base_tokens[3],\n",
    "        'processing_level': base_tokens[2]\n",
    "    }\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def create_item(metadata, assets):\n",
    "    item = pystac.Item(\n",
    "        id=metadata['id'],\n",
    "        datetime=metadata['start_datetime'],\n",
    "        start_datetime=metadata['start_datetime'],\n",
    "        end_datetime=metadata['end_datetime'],\n",
    "        geometry=metadata['geometry'],\n",
    "        collection=metadata['collection'],\n",
    "        bbox=None,\n",
    "        properties=metadata['properties']\n",
    "    )\n",
    "    # Add assets\n",
    "    for key, href in assets.items():\n",
    "        item.add_asset(key=key, asset=pystac.Asset(href=href))\n",
    "    return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a599c2b5-c346-43f1-bb38-42efe12fb557",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Reflectance Correction Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29748c49-101b-45ad-b7f0-079c87712b0c",
   "metadata": {},
   "source": [
    "Inputs and Configurations\n",
    "\n",
    "In the original pre-process, inputs are supplied by a run_config file. This consists of 2 entries (a reflectance file, uncertainty file, and a CRID).\n",
    "\n",
    "In the Unity system, the data files required will be staged in for the application, and the crid is a config item that is passed in. To make this work in Unity, we will also pass in an \"output collection\" which is needed if we want to \"persist\" the output products in the data catalog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbbc6339-b4ee-4282-ae70-ff8c017f9f5c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#Retrieve Reflectance Dataset\n",
    "input_dataset     = '/unity/ads/input_collections/REFLECT_CORRECT_MERGE/catalog.json' # type: stage-in\n",
    "#input_dataset    = '/unity/ads/input_collections/SBG-L2-RSRFL/catalog.json' # type: stage-in\n",
    "#input_L1B_dataset = '/unity/ads/input_collections/SBG-L1B-PRE/catalog.json' # type: stage-in\n",
    "output_stac_catalog_dir   = '/unity/ads/outputs/SBG-L2A_CORFL/' # type: stage-out\n",
    "\n",
    "output_collection_name    = 'urn:nasa:unity:unity:dev:SBG-L2A_CORFL___1'\n",
    "\n",
    "#Pre-process variables\n",
    "#From the config.json, retrieve the following information:\n",
    "crid = \"000\" #hardcoded but will be passed in\n",
    "experimental = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f265c43f-b678-4900-ab81-24cb13c89635",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Import Files from STAC Item Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "202ee5b4-03bf-4e06-9a5f-4a1ca2f1ae4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if2\n",
      "if2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[unity_sds_client.resources.DataFile(location=/unity/ads/input_collections/SBG-L2-RSRFL/./SISTER_EMIT_L2A_RSRFL_20240103T131936_001.bin),\n",
       " unity_sds_client.resources.DataFile(location=/unity/ads/input_collections/SBG-L2-RSRFL/./SISTER_EMIT_L2A_RSRFL_20240103T131936_001.hdr),\n",
       " unity_sds_client.resources.DataFile(location=/unity/ads/input_collections/SBG-L2-RSRFL/./SISTER_EMIT_L2A_RSRFL_20240103T131936_001_UNC.bin),\n",
       " unity_sds_client.resources.DataFile(location=/unity/ads/input_collections/SBG-L2-RSRFL/./SISTER_EMIT_L2A_RSRFL_20240103T131936_001_UNC.hdr),\n",
       " unity_sds_client.resources.DataFile(location=/unity/ads/input_collections/SBG-L1B-PRE/./SISTER_EMIT_L1B_RDN_20240103T131936_001.bin),\n",
       " unity_sds_client.resources.DataFile(location=/unity/ads/input_collections/SBG-L1B-PRE/./SISTER_EMIT_L1B_RDN_20240103T131936_001_LOC.bin),\n",
       " unity_sds_client.resources.DataFile(location=/unity/ads/input_collections/SBG-L1B-PRE/./SISTER_EMIT_L1B_RDN_20240103T131936_001_OBS.bin)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inp_collection = Collection.from_stac(input_dataset)\n",
    "\n",
    "data_filenames = inp_collection.data_files(['data'])\n",
    "data_filenames "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a35d73f-1188-43de-91b6-e8ab728543bb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Get the data files from the STAC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "400c89d8-c346-4ef1-8e42-55cba88a8005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/unity/ads/input_collections/SBG-L2-RSRFL/./SISTER_EMIT_L2A_RSRFL_20240103T131936_001.bin\n",
      "/unity/ads/input_collections/SBG-L1B-PRE/./SISTER_EMIT_L1B_RDN_20240103T131936_001_OBS.bin\n",
      "SISTER_EMIT_L2A_RSRFL_20240103T131936_001\n",
      "SISTER_EMIT_L1B_RDN_20240103T131936_001_OBS\n"
     ]
    }
   ],
   "source": [
    "for datafile in data_filenames:\n",
    "    f = datafile.location\n",
    "    if 'L1B_RDN' in f:\n",
    "        if \"_OBS.bin\" in f:\n",
    "           print(f)\n",
    "           obs_base_name = Path(f).stem\n",
    "           obs_file = f\n",
    "        else:\n",
    "            continue    \n",
    "    elif \"L2A_RSRFL\" in f:\n",
    "        if \"_UNC.bin\" in f:\n",
    "            continue\n",
    "            # print(f)\n",
    "            # obs_base_name = Path(f).stem\n",
    "            # obs_file = f\n",
    "        elif \".bin\" in f:\n",
    "            print(f)\n",
    "            rfl_base_name = Path(f).stem\n",
    "            rfl_file = f\n",
    "    else:\n",
    "        continue\n",
    "   \n",
    "print(rfl_base_name)\n",
    "print(obs_base_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8911421c-d454-47b1-8287-863009ca8a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 18:51:59,625 INFO: Starting reflect_correct.py\n"
     ]
    }
   ],
   "source": [
    "# Set up console logging using root logger\n",
    "logging.basicConfig(format=\"%(asctime)s %(levelname)s: %(message)s\", level=logging.INFO)\n",
    "logger = logging.getLogger(\"sister-reflect_correct\")\n",
    "# Set up file handler logging\n",
    "handler = logging.FileHandler(\"pge_run.log\")\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\"%(asctime)s %(levelname)s [%(module)s]: %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "logger.info(\"Starting reflect_correct.py\")\n",
    "\n",
    "if experimental:\n",
    "    disclaimer = \"(DISCLAIMER: THIS DATA IS EXPERIMENTAL AND NOT INTENDED FOR SCIENTIFIC USE) \"\n",
    "else:\n",
    "    disclaimer = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0722a36-f921-4bfe-bc07-76fc38e07552",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists(output_stac_catalog_dir):\n",
    "    os.mkdir(output_stac_catalog_dir)\n",
    "\n",
    "# rfl_base_name = os.path.basename(run_config['inputs']['reflectance_dataset'])\n",
    "sister,sensor,level,product,datetime,in_crid = rfl_base_name.split('_')\n",
    "\n",
    "# rfl_file = f'{run_config[\"inputs\"][\"reflectance_dataset\"]}/{rfl_base_name}.bin'\n",
    "\n",
    "out_rfl_file =  f'{output_stac_catalog_dir}/SISTER_{sensor}_L2A_CORFL_{datetime}_{crid}.bin'\n",
    "\n",
    "#obs_base_name = os.path.basename(run_config['inputs']['observation_dataset'])\n",
    "#obs_file = f'{run_config[\"inputs\"][\"observation_dataset\"]}/{obs_base_name}.bin'\n",
    "\n",
    "# Load input file\n",
    "anc_files = dict(zip(anc_names,[[obs_file,a] for a in range(len(anc_names))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62cad428-8a4d-47fd-b05f-ecdd268a3d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 18:52:22,277 INFO: Calculating topo coefficients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reflectance and ancillary no data extents do not match, combining no data masks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 18:52:23,492 ERROR: Errror calculating topo corrections.\n",
      "2024-02-22 18:52:23,495 INFO: Setting glint coefficients\n",
      "2024-02-22 18:52:23,499 INFO: Exporting corrected image\n"
     ]
    }
   ],
   "source": [
    "rfl = ht.HyTools()\n",
    "rfl.read_file(rfl_file,'envi',anc_files)\n",
    "rfl.create_bad_bands([[300,400],[1337,1430],[1800,1960],[2450,2600]])\n",
    "\n",
    "if sensor in ['PRISMA','DESIS','EMIT']:\n",
    "    corrections = ['Topographic','Glint']\n",
    "else:\n",
    "    corrections = ['Topographic','BRDF','Glint']\n",
    "\n",
    "#Run corrections\n",
    "if 'Topographic' in corrections:\n",
    "    logger.info('Calculating topo coefficients')\n",
    "    rfl.mask['calc_topo'] =  mask_create(rfl,config_dict['topo']['calc_mask'])\n",
    "    rfl.mask['apply_topo'] =  mask_create(rfl,config_dict['topo']['apply_mask'])\n",
    "    try: \n",
    "        calc_scsc_coeffs(rfl,config_dict['topo'])\n",
    "        rfl.corrections.append('topo')\n",
    "    except:\n",
    "        logger.error(\"Errror calculating topo corrections.\")\n",
    "        pass\n",
    "    \n",
    "if 'BRDF' in corrections:\n",
    "    logger.info('Calculating BRDF coefficients')\n",
    "    set_brdf(rfl,config_dict['brdf'])\n",
    "    set_solar_zn(rfl)\n",
    "    rfl.mask['calc_brdf'] =  mask_create(rfl,config_dict['brdf']['calc_mask'])\n",
    "    calc_flex_single(rfl,config_dict['brdf'])\n",
    "    rfl.corrections.append('brdf')\n",
    "    \n",
    "if 'Glint' in corrections:\n",
    "    try:\n",
    "        logger.info('Setting glint coefficients')\n",
    "        rfl.glint = config_dict['glint']\n",
    "        rfl.corrections.append('glint')\n",
    "    except:\n",
    "        logger.error(\"Errror calculating glint corrections.\")\n",
    "        pass\n",
    "\n",
    "#Export corrected reflectance\n",
    "header_dict = rfl.get_header()\n",
    "header_dict['description'] =f'{\" \".join(corrections)} corrected reflectance'\n",
    "\n",
    "logger.info('Exporting corrected image')\n",
    "writer = WriteENVI(out_rfl_file,header_dict)\n",
    "iterator = rfl.iterate(by='line', corrections=rfl.corrections)\n",
    "while not iterator.complete:\n",
    "    line = iterator.read_next()\n",
    "    writer.write_line(line,iterator.current_line)\n",
    "writer.close()\n",
    "\n",
    "generate_quicklook(out_rfl_file)\n",
    "\n",
    "# Take care of disclaimer in ENVI header and rename files\n",
    "if experimental:\n",
    "    out_hdr_file = out_rfl_file.replace(\".bin\", \".hdr\")\n",
    "    hdr = parse_envi_header(out_hdr_file)\n",
    "    hdr[\"description\"] = disclaimer + hdr[\"description\"].capitalize()\n",
    "    write_envi_header(out_hdr_file, hdr)\n",
    "    for file in glob.glob(f\"{output_stac_catalog_dir}/SISTER*\"):\n",
    "        shutil.move(file, f\"{output_stac_catalog_dir}/EXPERIMENTAL-{os.path.basename(file)}\")\n",
    "\n",
    "corfl_file = glob.glob(output_stac_catalog_dir+\"/*%s.bin\" % crid)[0]\n",
    "corfl_basename = os.path.basename(corfl_file)[:-4]\n",
    "\n",
    "#output_runconfig_path = f'{output_stac_catalog_dir}/{corfl_basename}.runconfig.json'\n",
    "#shutil.copyfile(run_config_json, output_runconfig_path)\n",
    "\n",
    "output_log_path = f'{output_stac_catalog_dir}/{corfl_basename}.log'\n",
    "if os.path.exists(\"pge_run.log\"):\n",
    "    shutil.copyfile('pge_run.log', output_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "741aa1e9-7fdf-494e-b209-a068980cd73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Add items for data products\n",
    "hdr_files = glob.glob(output_stac_catalog_dir + \"/*SISTER*.hdr\")\n",
    "hdr_files.sort()\n",
    "for hdr_file in hdr_files:\n",
    "    # TODO: Use incoming item.json to get properties and geometry and use hdr_file for description (?)\n",
    "    metadata = generate_stac_metadata(hdr_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95612056-d202-4df3-af62-0a9f7a211dba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Uncertain about this part. What is supposed to get sent out to STAC? \n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Create a collection\n",
    "out_collection = Collection(output_collection_name)\n",
    "\n",
    "# Add output file(s) to the dataset\n",
    "file = glob.glob(f\"{output_stac_catalog_dir}/*{crid}*.hdr\")\n",
    "\n",
    "if file:\n",
    "    header = envi.read_envi_header(file[0])    \n",
    "    start_time = metadata['start_datetime']\n",
    "    end_time = metadata['end_datetime']\n",
    "    # Create a Dataset for the collection\n",
    "    name = os.path.splitext(os.path.basename(file[0]))[0]\n",
    "    dataset = Dataset(\n",
    "        name=name,\n",
    "        collection_id=out_collection.collection_id, \n",
    "        start_time=start_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "        end_time=end_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "        creation_time=datetime.utcnow().replace(tzinfo=timezone.utc).isoformat(),\n",
    "        )\n",
    "    \n",
    "    for file in glob.glob(f\"{output_stac_catalog_dir}/*{crid}*\"):  \n",
    "\n",
    "        if file.endswith(\".bin\"):\n",
    "            dataset.add_data_file(DataFile(\"binary\", file, [\"data\"]))\n",
    "        elif file.endswith(\".png\"):\n",
    "            dataset.add_data_file(DataFile(\"image/png\", file, [\"browse\"]))\n",
    "        elif file.endswith(\".hdr\"):\n",
    "            dataset.add_data_file(DataFile(\"header\", file, [\"data\"]))\n",
    "        else:\n",
    "            dataset.add_data_file(DataFile(None, file, [\"metadata\"]))\n",
    "\n",
    "    dataset.add_data_file(DataFile(\"text/json\", output_stac_catalog_dir + '/' +  name +'.json', [\"metadata\"]))\n",
    "\n",
    "\n",
    "# Add the dataset to the collection\n",
    "out_collection._datasets.append(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2017b1c2-e466-4f4d-b36a-500cea35cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "Collection.to_stac(out_collection, output_stac_catalog_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93c728a-943e-4c73-8aa8-00017f39df5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
